{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "current_epsilon = 1.0\n",
    "data_path = Path(f\"data/train_{current_epsilon}.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating train and test targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets as skd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = skd.fetch_20newsgroups(data_home='.', remove=('headers'), random_state=0)\n",
    "test = skd.fetch_20newsgroups(subset='test', data_home='.', remove=('headers'), random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "train_names = [os.path.basename(f) for f in a.filenames]\n",
    "test_names  = [os.path.basename(f) for f in test.filenames]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing output from _Parma_ to be able to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary_map():\n",
    "    with open('vocabulary.txt', 'r') as vf:\n",
    "        m = {v: i for i,v in enumerate(vf.read().splitlines())}\n",
    "    return m\n",
    "\n",
    "def extract_docId(key):\n",
    "    split = key.split('_')\n",
    "    doc, word = split[0], split[1]\n",
    "    return doc\n",
    "\n",
    "def extract_wordId(key, vocab):\n",
    "    split = key.split('_')\n",
    "    doc, word = split[0], split[1]\n",
    "    return vocab.get(word, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              key     count  docId  wordId\n",
      "0     10000_chong  3.016004  10000   19438\n",
      "1  10000_frampton  2.229746  10000   19142\n",
      "2        10000_in  2.822721  10000      29\n",
      "3       10000_not -1.216612  10000     721\n",
      "4     10000_steve  0.733624  10000    3645\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_path, header=0, names=['key','count'], sep='\\t', index_col=False)\n",
    "vocab = build_vocabulary_map()\n",
    "df['docId'] = df['key'].apply(lambda r: extract_docId(r)).astype(str)\n",
    "df['wordId'] = df['key'].apply(lambda r: extract_wordId(r, vocab))\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "key       1027120\n",
       "count     1025774\n",
       "docId        9818\n",
       "wordId      41667\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['docId','wordId','count']].to_csv('processed.csv', index=False, header=False)\n",
    "df[['docId','wordId','count']].to_csv('processed_no_header.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>wordId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.027120e+06</td>\n",
       "      <td>1.027120e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.871309e+00</td>\n",
       "      <td>5.414886e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.852283e+00</td>\n",
       "      <td>9.839369e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-6.599269e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.466165e-01</td>\n",
       "      <td>4.550000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.309618e+00</td>\n",
       "      <td>1.234000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.419032e+00</td>\n",
       "      <td>5.148000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.061066e+02</td>\n",
       "      <td>5.490100e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count        wordId\n",
       "count  1.027120e+06  1.027120e+06\n",
       "mean   1.871309e+00  5.414886e+03\n",
       "std    3.852283e+00  9.839369e+03\n",
       "min   -6.599269e+00  0.000000e+00\n",
       "25%    5.466165e-01  4.550000e+02\n",
       "50%    1.309618e+00  1.234000e+03\n",
       "75%    2.419032e+00  5.148000e+03\n",
       "max    1.061066e+02  5.490100e+04"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.sparse import lil_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[['docId','wordId','count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_docids = set(train_df['docId'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "docid_to_ix = {docid: i for i, docid in enumerate(unique_docids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csr_matrix_from_output(dataframe, vocab, docid_to_ix_mapping):\n",
    "    M = lil_matrix( (len(docid_to_ix_mapping), len(vocab)), dtype=np.float)\n",
    "    for row in dataframe.itertuples():\n",
    "        ix = docid_to_ix_mapping[row.docId]\n",
    "        M[ix, row.wordId] = row.count\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "csr = create_csr_matrix_from_output(train_df, vocab, docid_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "target = np.full((csr.shape[0],), fill_value=-1, dtype=np.int)\n",
    "train_names = [os.path.basename(f) for f in a.filenames]\n",
    "docid_to_target = dict(zip(train_names, a.target))\n",
    "\n",
    "target = np.full((csr.shape[0],), fill_value=-1, dtype=np.int)\n",
    "for docId, ix_in_csr in docid_to_ix.items():\n",
    "    catId = docid_to_target.get(docId)\n",
    "    if catId is not None:\n",
    "        target[ix_in_csr] = catId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert csr.shape[0] == len(target) and target.min() >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9, 13, 19, ..., 15,  8, 19])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop\n",
    "Taken from https://scikit-learn.org/stable/auto_examples/model_selection/grid_search_text_feature_extraction.html#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#         Peter Prettenhofer <peter.prettenhofer@gmail.com>\n",
    "#         Mathieu Blondel <mathieu@mblondel.org>\n",
    "# License: BSD 3 clause\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Load some categories from the training set\n",
    "# categories = [\n",
    "#     'alt.atheism',\n",
    "#     'talk.religion.misc',\n",
    "# ]\n",
    "# Uncomment the following to do the analysis on all the categories\n",
    "categories = None\n",
    "\n",
    "# print(\"Loading 20 newsgroups dataset for categories:\")\n",
    "# print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# Define a pipeline combining a text feature extractor with a simple\n",
    "# classifier\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncommenting more parameters will give better exploring power but will\n",
    "# increase processing time in a combinatorial way\n",
    "parameters = {\n",
    "#     'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    # 'vect__max_features': (None, 5000, 10000, 50000),\n",
    "#     'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__max_iter': (20,),\n",
    "    'clf__alpha': (0.00001, 0.000001),\n",
    "    'clf__penalty': ('l2', 'elasticnet'),\n",
    "    # 'clf__max_iter': (10, 50, 80),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['tfidf', 'clf']\n",
      "parameters:\n",
      "{'clf__alpha': (1e-05, 1e-06),\n",
      " 'clf__max_iter': (20,),\n",
      " 'clf__penalty': ('l2', 'elasticnet'),\n",
      " 'tfidf__norm': ('l1', 'l2'),\n",
      " 'tfidf__use_idf': (True, False)}\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   19.3s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   52.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 57.884s\n",
      "\n",
      "Best score: 0.714\n",
      "Best parameters set:\n",
      "\tclf__alpha: 1e-06\n",
      "\tclf__max_iter: 20\n",
      "\tclf__penalty: 'elasticnet'\n",
      "\ttfidf__norm: 'l1'\n",
      "\ttfidf__use_idf: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/crac/Downloads/1- thesis related/parma/NaiveBayes/Python_Files/.venv/parma/lib64/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# multiprocessing requires the fork to happen in a __main__ protected\n",
    "# block\n",
    "\n",
    "# find the best parameters for both the feature extraction and the\n",
    "# classifier\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "grid_search.fit(csr, target)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model for this epsilon\n",
    "import pickle\n",
    "with open('best_clf_sgd_{}'.format(current_epsilon), 'wb') as f:\n",
    "    pickle.dump(grid_search.best_estimator_, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessment\n",
    "## Creating data that compatible with the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(s):\n",
    "    r = s.replace('\\n', ' ').lower().replace(',',' ').replace('  ', ' ')\n",
    "    if r == '':\n",
    "        r = ' '\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# We need to recreate a CSR matrix from the test data\n",
    "def create_test_data(sklearn_data, vocab):\n",
    "    \n",
    "    test_names  = set(os.path.basename(f) for f in sklearn_data.filenames)\n",
    "    docid_to_ix_mapping = {docid: i for i, docid in enumerate(test_names)}\n",
    "    preprocessed_strings = dict()\n",
    "    \n",
    "    # Preprocess the target's text as if it would come from Parma\n",
    "    for docPath, d in zip(sklearn_data.filenames, sklearn_data.data):\n",
    "        docId = os.path.basename(docPath)\n",
    "        clean_content = clean_text(d)\n",
    "        if docId not in preprocessed_strings:\n",
    "            preprocessed_strings[docId] = clean_content\n",
    "    \n",
    "    # Create test word count mapping\n",
    "    M = lil_matrix( (len(docid_to_ix_mapping), len(vocab)), dtype=np.float)\n",
    "    for docId, csr_ix in docid_to_ix_mapping.items():\n",
    "        associated_text = preprocessed_strings.get(docId)\n",
    "        if associated_text is None:\n",
    "            raise ValueError(\"Should not happen\")\n",
    "            \n",
    "        for token in associated_text.split(' '):\n",
    "            token_ix = vocab.get(token)\n",
    "            if token_ix is not None:\n",
    "                M[csr_ix, token_ix] += 1\n",
    "\n",
    "    # Create test target data\n",
    "    test_target = np.full((M.shape[0],), fill_value=-1, dtype=np.int)\n",
    "#     assert len(test_target) == len(sklearn_data.target) and len(test_target) == M.shape[0]\n",
    "    \n",
    "    test_names = [os.path.basename(f) for f in sklearn_data.filenames]\n",
    "    docid_to_target = dict(zip(test_names, sklearn_data.target))\n",
    "\n",
    "    for docId, csr_ix in docid_to_ix_mapping.items():\n",
    "        catId = docid_to_target.get(docId)\n",
    "        if catId is not None:\n",
    "            test_target[csr_ix] = catId\n",
    "        else:\n",
    "            print(docId, csr_ix)\n",
    "            print\n",
    "            raise ValueError(\"Should not happen\")\n",
    "            \n",
    "    return M, test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csr, test_target = create_test_data(test, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6871,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pred = best_clf.predict(test_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.647358463105807"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true=test_target, y_pred=pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "probability estimates are not available for loss='hinge'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-c6e16576b7a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_log_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_csr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Downloads/1- thesis related/parma/NaiveBayes/Python_Files/.venv/parma/lib64/python3.7/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, type)\u001b[0m\n\u001b[1;32m    108\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                     \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattribute_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/1- thesis related/parma/NaiveBayes/Python_Files/.venv/parma/lib64/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36mpredict_log_proba\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m         \"\"\"\n\u001b[0;32m-> 1064\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_log_proba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/1- thesis related/parma/NaiveBayes/Python_Files/.venv/parma/lib64/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36m_check_proba\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"log\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"modified_huber\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m             raise AttributeError(\"probability estimates are not available for\"\n\u001b[0;32m--> 956\u001b[0;31m                                  \" loss=%r\" % self.loss)\n\u001b[0m\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: probability estimates are not available for loss='hinge'"
     ]
    }
   ],
   "source": [
    "best_clf.predict_log_proba(test_csr[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
